steps:
- name: 'gcr.io/cloud-builders/docker'
  id: Pull docker cache
  entrypoint: 'bash'
  args:
  - '-c'
  - |
   docker pull gcr.io/my-lab1-326317/airflow-dags-builder:latest || exit 0
- name: gcr.io/cloud-builders/docker
  id: Build Airflow DAGs Builder
  args: [
      'build',
      '-t', 'gcr.io/$PROJECT_ID/airflow-dags-builder',
      '--cache-from', 'gcr.io/my-lab1-326317/airflow-dags-builder:latest',
      './'
    ]
- name: 'gcr.io/$PROJECT_ID/airflow-dags-builder'
  id: Validation Test
  # Validate the integrity of the DAG files.
  entrypoint: python
  env:
  - AIRFLOW__CORE__DAGS_FOLDER=/workspace/dags
  args:
  - -m
  - unittest
  - tests/dag_integrity_test.py
images: ['gcr.io/$PROJECT_ID/airflow-dags-builder:latest']

# - name: gcr.io/google.com/cloudsdktool/cloud-sdk
#   id: Deploy
#   entrypoint: bash
#   args: [ '-c', 'if [ "$BRANCH_NAME" == "develop" ]; then echo "$BRANCH_NAME" && gsutil -m rsync -d -r ./dags gs://${_COMPOSER_BUCKET}/dags; else echo "Working on $BRANCH_NAME"; fi']
# substitutions:
#     _COMPOSER_BUCKET: us-central1-my-demo-408f667a-bucket
# # options:
# #   logging: CLOUD_LOGGING_ONLY
# logsBucket: 'gs://mylogsbucket123'